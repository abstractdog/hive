PREHOOK: query: DROP TABLE accumulo_table_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_1
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE accumulo_table_1(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_0")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_1
POSTHOOK: query: CREATE TABLE accumulo_table_1(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_0")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_1
PREHOOK: query: DESCRIBE EXTENDED accumulo_table_1
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@accumulo_table_1
POSTHOOK: query: DESCRIBE EXTENDED accumulo_table_1
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@accumulo_table_1
key                 	int                 	from deserializer   
value               	string              	from deserializer   
	 	 
#### A masked pattern was here ####
PREHOOK: query: select * from accumulo_table_1
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
#### A masked pattern was here ####
POSTHOOK: query: select * from accumulo_table_1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
#### A masked pattern was here ####
PREHOOK: query: EXPLAIN FROM src INSERT OVERWRITE TABLE accumulo_table_1 SELECT * WHERE (key%2)=0
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN FROM src INSERT OVERWRITE TABLE accumulo_table_1 SELECT * WHERE (key%2)=0
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage
  Stage-2
  Stage-1 is a root stage
  Stage-3 is a root stage

STAGE PLANS:
  Stage: Stage-0
      Alter Table Operator:
        Alter Table
          type: drop props
          old name: default.accumulo_table_1
          properties:
            COLUMN_STATS_ACCURATE 

  Stage: Stage-2
      Insert operator:
        Insert

  Stage: Stage-1
      Pre Insert operator:
        Pre-Insert task

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: ((UDFToDouble(key) % 2.0) = 0.0) (type: boolean)
              Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: UDFToInteger(key) (type: int), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat
                      output format: org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat
                      serde: org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe
                      name: default.accumulo_table_1

PREHOOK: query: FROM src INSERT OVERWRITE TABLE accumulo_table_1 SELECT * WHERE (key%2)=0
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_1
POSTHOOK: query: FROM src INSERT OVERWRITE TABLE accumulo_table_1 SELECT * WHERE (key%2)=0
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_1
PREHOOK: query: DROP TABLE accumulo_table_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_2
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE EXTERNAL TABLE accumulo_table_2(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_0")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_2
POSTHOOK: query: CREATE EXTERNAL TABLE accumulo_table_2(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_0")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_2
PREHOOK: query: EXPLAIN 
SELECT Y.* 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.* FROM src) Y
ON (x.key = Y.key)
ORDER BY key, value LIMIT 20
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN 
SELECT Y.* 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.* FROM src) Y
ON (x.key = Y.key)
ORDER BY key, value LIMIT 20
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: accumulo_table_1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: UDFToDouble(_col0) (type: double)
                  sort order: +
                  Map-reduce partition columns: UDFToDouble(_col0) (type: double)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: UDFToDouble(_col0) (type: double)
                  sort order: +
                  Map-reduce partition columns: UDFToDouble(_col0) (type: double)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 UDFToDouble(_col0) (type: double)
            1 UDFToDouble(_col0) (type: double)
          outputColumnNames: _col1, _col2
          Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col1 (type: string), _col2 (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: string), _col1 (type: string)
              sort order: ++
              Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
              TopN Hash Memory Usage: 0.1
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 550 Data size: 5843 Basic stats: COMPLETE Column stats: NONE
          Limit
            Number of rows: 20
            Statistics: Num rows: 20 Data size: 200 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 20 Data size: 200 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink

PREHOOK: query: SELECT Y.* 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.* FROM src) Y
ON (x.key = Y.key)
ORDER BY key, value LIMIT 20
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT Y.* 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.* FROM src) Y
ON (x.key = Y.key)
ORDER BY key, value LIMIT 20
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
104	val_104
104	val_104
114	val_114
116	val_116
118	val_118
118	val_118
12	val_12
12	val_12
120	val_120
120	val_120
126	val_126
128	val_128
128	val_128
128	val_128
PREHOOK: query: EXPLAIN 
SELECT Y.*
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1 WHERE 100 < accumulo_table_1.key) x
JOIN 
(SELECT accumulo_table_2.* FROM accumulo_table_2 WHERE accumulo_table_2.key < 120) Y
ON (x.key = Y.key)
ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN 
SELECT Y.*
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1 WHERE 100 < accumulo_table_1.key) x
JOIN 
(SELECT accumulo_table_2.* FROM accumulo_table_2 WHERE accumulo_table_2.key < 120) Y
ON (x.key = Y.key)
ORDER BY key, value
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: accumulo_table_1
            filterExpr: ((100 < key) and (key < 120)) (type: boolean)
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: key (type: int)
              outputColumnNames: _col0
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          TableScan
            alias: accumulo_table_2
            filterExpr: ((key < 120) and (100 < key)) (type: boolean)
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Select Operator
              expressions: key (type: int), value (type: string)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Reduce Output Operator
                key expressions: _col0 (type: int)
                sort order: +
                Map-reduce partition columns: _col0 (type: int)
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                value expressions: _col1 (type: string)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
          outputColumnNames: _col1, _col2
          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          Select Operator
            expressions: _col1 (type: int), _col2 (type: string)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: int), _col1 (type: string)
              sort order: ++
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
      Reduce Operator Tree:
        Select Operator
          expressions: KEY.reducesinkkey0 (type: int), KEY.reducesinkkey1 (type: string)
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT Y.*
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1 WHERE 100 < accumulo_table_1.key) x
JOIN 
(SELECT accumulo_table_2.* FROM accumulo_table_2 WHERE accumulo_table_2.key < 120) Y
ON (x.key = Y.key)
ORDER BY key,value
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Input: default@accumulo_table_2
#### A masked pattern was here ####
POSTHOOK: query: SELECT Y.*
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1 WHERE 100 < accumulo_table_1.key) x
JOIN 
(SELECT accumulo_table_2.* FROM accumulo_table_2 WHERE accumulo_table_2.key < 120) Y
ON (x.key = Y.key)
ORDER BY key,value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Input: default@accumulo_table_2
#### A masked pattern was here ####
0	val_0
2	val_2
4	val_4
8	val_8
10	val_10
12	val_12
18	val_18
20	val_20
24	val_24
26	val_26
28	val_28
30	val_30
34	val_34
42	val_42
44	val_44
54	val_54
58	val_58
64	val_64
66	val_66
70	val_70
72	val_72
74	val_74
76	val_76
78	val_78
80	val_80
82	val_82
84	val_84
86	val_86
90	val_90
92	val_92
96	val_96
98	val_98
100	val_100
104	val_104
114	val_114
116	val_116
118	val_118
120	val_120
126	val_126
128	val_128
134	val_134
136	val_136
138	val_138
146	val_146
150	val_150
152	val_152
156	val_156
158	val_158
160	val_160
162	val_162
164	val_164
166	val_166
168	val_168
170	val_170
172	val_172
174	val_174
176	val_176
178	val_178
180	val_180
186	val_186
190	val_190
192	val_192
194	val_194
196	val_196
200	val_200
202	val_202
208	val_208
214	val_214
216	val_216
218	val_218
222	val_222
224	val_224
226	val_226
228	val_228
230	val_230
238	val_238
242	val_242
244	val_244
248	val_248
252	val_252
256	val_256
258	val_258
260	val_260
262	val_262
266	val_266
272	val_272
274	val_274
278	val_278
280	val_280
282	val_282
284	val_284
286	val_286
288	val_288
292	val_292
296	val_296
298	val_298
302	val_302
306	val_306
308	val_308
310	val_310
316	val_316
318	val_318
322	val_322
332	val_332
336	val_336
338	val_338
342	val_342
344	val_344
348	val_348
356	val_356
360	val_360
362	val_362
364	val_364
366	val_366
368	val_368
374	val_374
378	val_378
382	val_382
384	val_384
386	val_386
392	val_392
394	val_394
396	val_396
400	val_400
402	val_402
404	val_404
406	val_406
414	val_414
418	val_418
424	val_424
430	val_430
432	val_432
436	val_436
438	val_438
444	val_444
446	val_446
448	val_448
452	val_452
454	val_454
458	val_458
460	val_460
462	val_462
466	val_466
468	val_468
470	val_470
472	val_472
478	val_478
480	val_480
482	val_482
484	val_484
490	val_490
492	val_492
494	val_494
496	val_496
498	val_498
PREHOOK: query: DROP TABLE empty_accumulo_table
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE empty_accumulo_table
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE empty_accumulo_table(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@empty_accumulo_table
POSTHOOK: query: CREATE TABLE empty_accumulo_table(key int, value string) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,cf:string")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@empty_accumulo_table
PREHOOK: query: DROP TABLE empty_normal_table
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE empty_normal_table
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE empty_normal_table(key int, value string)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@empty_normal_table
POSTHOOK: query: CREATE TABLE empty_normal_table(key int, value string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@empty_normal_table
PREHOOK: query: select * from (select count(1) as c from empty_normal_table union all select count(1) as c from empty_accumulo_table) x order by c
PREHOOK: type: QUERY
PREHOOK: Input: default@empty_accumulo_table
PREHOOK: Input: default@empty_normal_table
#### A masked pattern was here ####
POSTHOOK: query: select * from (select count(1) as c from empty_normal_table union all select count(1) as c from empty_accumulo_table) x order by c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@empty_accumulo_table
POSTHOOK: Input: default@empty_normal_table
#### A masked pattern was here ####
0
0
PREHOOK: query: select * from (select count(1) c from empty_normal_table union all select count(1) as c from accumulo_table_1) x order by c
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Input: default@empty_normal_table
#### A masked pattern was here ####
POSTHOOK: query: select * from (select count(1) c from empty_normal_table union all select count(1) as c from accumulo_table_1) x order by c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Input: default@empty_normal_table
#### A masked pattern was here ####
0
155
PREHOOK: query: select * from (select count(1) c from src union all select count(1) as c from empty_accumulo_table) x order by c
PREHOOK: type: QUERY
PREHOOK: Input: default@empty_accumulo_table
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select * from (select count(1) c from src union all select count(1) as c from empty_accumulo_table) x order by c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@empty_accumulo_table
POSTHOOK: Input: default@src
#### A masked pattern was here ####
0
500
PREHOOK: query: select * from (select count(1) c from src union all select count(1) as c from accumulo_table_1) x order by c
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: select * from (select count(1) c from src union all select count(1) as c from accumulo_table_1) x order by c
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Input: default@src
#### A masked pattern was here ####
155
500
PREHOOK: query: CREATE TABLE accumulo_table_3(key int, value string, count int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,cf:val,cf2:count"
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_3
POSTHOOK: query: CREATE TABLE accumulo_table_3(key int, value string, count int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,cf:val,cf2:count"
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_3
PREHOOK: query: EXPLAIN 
INSERT OVERWRITE TABLE accumulo_table_3
SELECT x.key, x.value, Y.count 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.key, count(src.key) as count FROM src GROUP BY src.key) Y
ON (x.key = Y.key)
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN 
INSERT OVERWRITE TABLE accumulo_table_3
SELECT x.key, x.value, Y.count 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.key, count(src.key) as count FROM src GROUP BY src.key) Y
ON (x.key = Y.key)
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage
  Stage-2
  Stage-1 is a root stage
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-0
      Alter Table Operator:
        Alter Table
          type: drop props
          old name: default.accumulo_table_3
          properties:
            COLUMN_STATS_ACCURATE 

  Stage: Stage-2
      Insert operator:
        Insert

  Stage: Stage-1
      Pre Insert operator:
        Pre-Insert task

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: count(key)
                keys: key (type: string)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: accumulo_table_1
            Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
              Select Operator
                expressions: key (type: int), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                Reduce Output Operator
                  key expressions: UDFToDouble(_col0) (type: double)
                  sort order: +
                  Map-reduce partition columns: UDFToDouble(_col0) (type: double)
                  Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE
                  value expressions: _col0 (type: int), _col1 (type: string)
          TableScan
            Reduce Output Operator
              key expressions: UDFToDouble(_col0) (type: double)
              sort order: +
              Map-reduce partition columns: UDFToDouble(_col0) (type: double)
              Statistics: Num rows: 250 Data size: 2656 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 UDFToDouble(_col0) (type: double)
            1 UDFToDouble(_col0) (type: double)
          outputColumnNames: _col0, _col1, _col3
          Statistics: Num rows: 275 Data size: 2921 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: _col0 (type: int), _col1 (type: string), UDFToInteger(_col3) (type: int)
            outputColumnNames: _col0, _col1, _col2
            Statistics: Num rows: 275 Data size: 2921 Basic stats: COMPLETE Column stats: NONE
            File Output Operator
              compressed: false
              Statistics: Num rows: 275 Data size: 2921 Basic stats: COMPLETE Column stats: NONE
              table:
                  input format: org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat
                  output format: org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat
                  serde: org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe
                  name: default.accumulo_table_3

PREHOOK: query: INSERT OVERWRITE TABLE accumulo_table_3
SELECT x.key, x.value, Y.count 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.key, count(src.key) as count FROM src GROUP BY src.key) Y
ON (x.key = Y.key)
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_3
POSTHOOK: query: INSERT OVERWRITE TABLE accumulo_table_3
SELECT x.key, x.value, Y.count 
FROM 
(SELECT accumulo_table_1.* FROM accumulo_table_1) x
JOIN 
(SELECT src.key, count(src.key) as count FROM src GROUP BY src.key) Y
ON (x.key = Y.key)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_3
PREHOOK: query: select count(1) from accumulo_table_3
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
POSTHOOK: query: select count(1) from accumulo_table_3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
155
PREHOOK: query: select * from accumulo_table_3 order by key, value limit 5
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
POSTHOOK: query: select * from accumulo_table_3 order by key, value limit 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
0	val_0	3
2	val_2	1
4	val_4	1
8	val_8	1
10	val_10	1
PREHOOK: query: select key, count from accumulo_table_3 order by key, count desc limit 5
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
POSTHOOK: query: select key, count from accumulo_table_3 order by key, count desc limit 5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_3
#### A masked pattern was here ####
0	3
2	1
4	1
8	1
10	1
PREHOOK: query: DROP TABLE accumulo_table_4
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_4
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE accumulo_table_4(key int, value1 string, value2 int, value3 int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,a:b,a:c,d:e"
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_4
POSTHOOK: query: CREATE TABLE accumulo_table_4(key int, value1 string, value2 int, value3 int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,a:b,a:c,d:e"
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_4
PREHOOK: query: INSERT OVERWRITE TABLE accumulo_table_4 SELECT key, value, key+1, key+2 
FROM src WHERE key=98 OR key=100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_4
POSTHOOK: query: INSERT OVERWRITE TABLE accumulo_table_4 SELECT key, value, key+1, key+2 
FROM src WHERE key=98 OR key=100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_4
PREHOOK: query: SELECT * FROM accumulo_table_4 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_4
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM accumulo_table_4 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_4
#### A masked pattern was here ####
98	val_98	99	100
100	val_100	101	102
PREHOOK: query: DROP TABLE accumulo_table_5
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_5
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE EXTERNAL TABLE accumulo_table_5(key int, value map<string,string>) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,a:*")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_4")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_5
POSTHOOK: query: CREATE EXTERNAL TABLE accumulo_table_5(key int, value map<string,string>) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES ("accumulo.columns.mapping" = ":rowID,a:*")
TBLPROPERTIES ("accumulo.table.name" = "accumulo_table_4")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_5
PREHOOK: query: SELECT * FROM accumulo_table_5 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_5
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM accumulo_table_5 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_5
#### A masked pattern was here ####
98	{"b":"val_98","c":"99"}
100	{"b":"val_100","c":"101"}
PREHOOK: query: DROP TABLE accumulo_table_6
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_6
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE accumulo_table_6(key int, value map<string,string>) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,cf:*"
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_6
POSTHOOK: query: CREATE TABLE accumulo_table_6(key int, value map<string,string>) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,cf:*"
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_6
PREHOOK: query: INSERT OVERWRITE TABLE accumulo_table_6 SELECT key, map(value, key) FROM src
WHERE key=98 OR key=100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_6
POSTHOOK: query: INSERT OVERWRITE TABLE accumulo_table_6 SELECT key, map(value, key) FROM src
WHERE key=98 OR key=100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_6
PREHOOK: query: SELECT * FROM accumulo_table_6 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_6
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM accumulo_table_6 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_6
#### A masked pattern was here ####
98	{"val_98":"98"}
100	{"val_100":"100"}
PREHOOK: query: DROP TABLE accumulo_table_7
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_7
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE accumulo_table_7(value map<string,string>, key int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = "cf:*,:rowID"
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_7
POSTHOOK: query: CREATE TABLE accumulo_table_7(value map<string,string>, key int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = "cf:*,:rowID"
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_7
PREHOOK: query: INSERT OVERWRITE TABLE accumulo_table_7 
SELECT map(value, key, upper(value), key+1), key FROM src
WHERE key=98 OR key=100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_7
POSTHOOK: query: INSERT OVERWRITE TABLE accumulo_table_7 
SELECT map(value, key, upper(value), key+1), key FROM src
WHERE key=98 OR key=100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_7
PREHOOK: query: SELECT * FROM accumulo_table_7 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_7
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM accumulo_table_7 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_7
#### A masked pattern was here ####
{"VAL_98":"99.0","val_98":"98"}	98
{"VAL_100":"101.0","val_100":"100"}	100
PREHOOK: query: DROP TABLE accumulo_table_8
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE accumulo_table_8
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE accumulo_table_8(key int, value1 string, value2 int, value3 int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,a:b,a:c,d:e"
)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@accumulo_table_8
POSTHOOK: query: CREATE TABLE accumulo_table_8(key int, value1 string, value2 int, value3 int) 
STORED BY 'org.apache.hadoop.hive.accumulo.AccumuloStorageHandler'
WITH SERDEPROPERTIES (
"accumulo.columns.mapping" = ":rowID,a:b,a:c,d:e"
)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@accumulo_table_8
PREHOOK: query: INSERT OVERWRITE TABLE accumulo_table_8 SELECT key, value, key+1, key+2 
FROM src WHERE key=98 OR key=100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@accumulo_table_8
POSTHOOK: query: INSERT OVERWRITE TABLE accumulo_table_8 SELECT key, value, key+1, key+2 
FROM src WHERE key=98 OR key=100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@accumulo_table_8
PREHOOK: query: SELECT * FROM accumulo_table_8 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@accumulo_table_8
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM accumulo_table_8 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@accumulo_table_8
#### A masked pattern was here ####
98	val_98	99	100
100	val_100	101	102
PREHOOK: query: DROP TABLE accumulo_table_1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_1
PREHOOK: Output: default@accumulo_table_1
POSTHOOK: query: DROP TABLE accumulo_table_1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_1
POSTHOOK: Output: default@accumulo_table_1
PREHOOK: query: DROP TABLE accumulo_table_2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_2
PREHOOK: Output: default@accumulo_table_2
POSTHOOK: query: DROP TABLE accumulo_table_2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_2
POSTHOOK: Output: default@accumulo_table_2
PREHOOK: query: DROP TABLE accumulo_table_3
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_3
PREHOOK: Output: default@accumulo_table_3
POSTHOOK: query: DROP TABLE accumulo_table_3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_3
POSTHOOK: Output: default@accumulo_table_3
PREHOOK: query: DROP TABLE accumulo_table_4
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_4
PREHOOK: Output: default@accumulo_table_4
POSTHOOK: query: DROP TABLE accumulo_table_4
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_4
POSTHOOK: Output: default@accumulo_table_4
PREHOOK: query: DROP TABLE accumulo_table_5
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_5
PREHOOK: Output: default@accumulo_table_5
POSTHOOK: query: DROP TABLE accumulo_table_5
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_5
POSTHOOK: Output: default@accumulo_table_5
PREHOOK: query: DROP TABLE accumulo_table_6
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_6
PREHOOK: Output: default@accumulo_table_6
POSTHOOK: query: DROP TABLE accumulo_table_6
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_6
POSTHOOK: Output: default@accumulo_table_6
PREHOOK: query: DROP TABLE accumulo_table_7
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_7
PREHOOK: Output: default@accumulo_table_7
POSTHOOK: query: DROP TABLE accumulo_table_7
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_7
POSTHOOK: Output: default@accumulo_table_7
PREHOOK: query: DROP TABLE accumulo_table_8
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@accumulo_table_8
PREHOOK: Output: default@accumulo_table_8
POSTHOOK: query: DROP TABLE accumulo_table_8
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@accumulo_table_8
POSTHOOK: Output: default@accumulo_table_8
PREHOOK: query: DROP TABLE empty_accumulo_table
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@empty_accumulo_table
PREHOOK: Output: default@empty_accumulo_table
POSTHOOK: query: DROP TABLE empty_accumulo_table
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@empty_accumulo_table
POSTHOOK: Output: default@empty_accumulo_table
PREHOOK: query: DROP TABLE empty_normal_table
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@empty_normal_table
PREHOOK: Output: default@empty_normal_table
POSTHOOK: query: DROP TABLE empty_normal_table
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@empty_normal_table
POSTHOOK: Output: default@empty_normal_table
